# -*- coding: utf-8 -*-
# Copyright 2026 Sakura-é¢‘é“æ€»ç»“åŠ©æ‰‹
#
# æœ¬é¡¹ç›®é‡‡ç”¨ GNU Affero General Public License Version 3.0 (AGPL-3.0) è®¸å¯ï¼Œ
# å¹¶é™„åŠ éå•†ä¸šä½¿ç”¨é™åˆ¶æ¡æ¬¾ã€‚
#
# - ç½²åï¼šå¿…é¡»æä¾›æœ¬é¡¹ç›®çš„åŸå§‹æ¥æºé“¾æ¥
# - éå•†ä¸šï¼šç¦æ­¢ä»»ä½•å•†ä¸šç”¨é€”å’Œåˆ†å‘
# - ç›¸åŒæ–¹å¼å…±äº«ï¼šè¡ç”Ÿä½œå“å¿…é¡»é‡‡ç”¨ç›¸åŒçš„è®¸å¯è¯
#
# æœ¬é¡¹ç›®æºä»£ç ï¼šhttps://github.com/Sakura520222/Sakura-Channel-Summary-Assistant
# è®¸å¯è¯å…¨æ–‡ï¼šå‚è§ LICENSE æ–‡ä»¶

"""
è‡ªç„¶è¯­è¨€æ„å›¾è§£æå™¨
ç†è§£ç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾
"""

import logging
import re
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)


class IntentParser:
    """æ„å›¾è§£æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ„å›¾è§£æå™¨"""
        self.time_keywords = {
            "ä»Šå¤©": 0,
            "æ˜¨å¤©": 1,
            "å‰å¤©": 2,
            "æœ¬å‘¨": 7,
            "ä¸Šå‘¨": 14,
            "è¿™å‘¨": 7,
            "è¿™æœˆ": 30,
            "æœ¬æœˆ": 30,
            "ä¸Šæœˆ": 60,
            "æœ€è¿‘": 7,
            "è¿‘æœŸ": 7,
        }

    def parse_query(self, query: str) -> Dict[str, Any]:
        """
        è§£æç”¨æˆ·æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬

        Returns:
            {
                "intent": str,  # æ„å›¾ç±»å‹: summary, topic, keyword, stats, status
                "time_range": Optional[int],  # æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰
                "keywords": List[str],  # å…³é”®è¯
                "channel_id": Optional[str],  # é¢‘é“ID
                "original_query": str,  # åŸå§‹æŸ¥è¯¢
                "confidence": float  # ç½®ä¿¡åº¦
            }
        """
        query = query.strip()
        logger.info(f"è§£ææŸ¥è¯¢: {query}")

        result = {
            "original_query": query,
            "intent": "summary",
            "time_range": None,
            "keywords": [],
            "channel_id": None,
            "confidence": 0.0
        }

        # 1. æ£€æµ‹çŠ¶æ€æŸ¥è¯¢æ„å›¾
        if self._is_status_query(query):
            result["intent"] = "status"
            result["confidence"] = 0.9
            logger.info("è¯†åˆ«ä¸ºçŠ¶æ€æŸ¥è¯¢æ„å›¾")
            return result

        # 2. æ£€æµ‹ç»Ÿè®¡æŸ¥è¯¢æ„å›¾
        if self._is_stats_query(query):
            result["intent"] = "stats"
            result["confidence"] = 0.9
            logger.info("è¯†åˆ«ä¸ºç»Ÿè®¡æŸ¥è¯¢æ„å›¾")
            return result

        # 3. æå–æ—¶é—´èŒƒå›´
        time_range = self._extract_time_range(query)
        if time_range is not None:
            result["time_range"] = time_range
            logger.info(f"æå–æ—¶é—´èŒƒå›´: {time_range}å¤©")

        # 4. æå–å…³é”®è¯
        keywords = self._extract_keywords(query)
        if keywords:
            result["keywords"] = keywords
            result["intent"] = "keyword" if keywords else "summary"
            logger.info(f"æå–å…³é”®è¯: {keywords}")

        # 5. æ£€æµ‹ä¸»é¢˜æŸ¥è¯¢
        topics = self._extract_topics(query)
        if topics:
            result["keywords"].extend(topics)
            result["intent"] = "topic"
            logger.info(f"æå–ä¸»é¢˜: {topics}")

        # 6. è®¡ç®—ç½®ä¿¡åº¦
        if time_range or keywords or topics:
            result["confidence"] = 0.8
        else:
            result["confidence"] = 0.5
            result["intent"] = "summary"
            result["time_range"] = 7  # é»˜è®¤æŸ¥è¯¢æœ€è¿‘7å¤©

        return result

    def _is_status_query(self, query: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºçŠ¶æ€æŸ¥è¯¢"""
        status_keywords = [
            "é…é¢", "å‰©ä½™", "è¿˜èƒ½", "å‡ æ¬¡", "é™é¢",
            "quota", "remaining", "limit"
        ]
        query_lower = query.lower()
        return any(kw in query_lower for kw in status_keywords)

    def _is_stats_query(self, query: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç»Ÿè®¡æŸ¥è¯¢"""
        stats_keywords = [
            "ç»Ÿè®¡", "æ€»æ•°", "å¤šå°‘æ¡", "æœ‰å¤šå°‘", "æ•°é‡",
            "æ’å", "æ’è¡Œ", "top"
        ]
        query_lower = query.lower()
        return any(kw in query_lower for kw in stats_keywords)

    def _extract_time_range(self, query: str) -> Optional[int]:
        """æå–æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰"""
        # æ£€æŸ¥å…³é”®è¯
        for keyword, days in self.time_keywords.items():
            if keyword in query:
                return days

        # æ£€æŸ¥æ•°å­—+å¤©æ¨¡å¼
        pattern = r'(\d+)\s*[å¤©æ—¥]'
        match = re.search(pattern, query)
        if match:
            return int(match.group(1))

        # æ£€æŸ¥"æœ€è¿‘Nå¤©"æ¨¡å¼
        pattern = r'æœ€è¿‘\s*(\d+)\s*[å¤©æ—¥]'
        match = re.search(pattern, query)
        if match:
            return int(match.group(1))

        return None

    def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = []

        # ç§»é™¤æ—¶é—´å…³é”®è¯
        filtered_query = query
        for keyword in self.time_keywords.keys():
            filtered_query = filtered_query.replace(keyword, "")

        # å¸¸è§æŠ€æœ¯å…³é”®è¯
        tech_keywords = [
            "AI", "GPT", "ChatGPT", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ",
            "Python", "JavaScript", "Java", "ç¼–ç¨‹", "ä»£ç ",
            "API", "å¼€å‘", "æ¡†æ¶", "åº“", "å·¥å…·",
            "åŒºå—é“¾", "Web3", "åŠ å¯†è´§å¸", "NFT"
        ]

        for kw in tech_keywords:
            if kw.lower() in filtered_query.lower():
                keywords.append(kw)

        return keywords

    def _extract_topics(self, query: str) -> List[str]:
        """æå–ä¸»é¢˜"""
        topics = []

        # ä¸»é¢˜æ˜ å°„
        topic_patterns = {
            "æŠ€æœ¯": ["æŠ€æœ¯", "å¼€å‘", "ç¼–ç¨‹", "ä»£ç ", "AI"],
            "æ–°é—»": ["æ–°é—»", "èµ„è®¯", "å‘å¸ƒ", "å…¬å‘Š"],
            "è®¨è®º": ["è®¨è®º", "çœ‹æ³•", "è§‚ç‚¹", "è¯„è®º"],
            "æ›´æ–°": ["æ›´æ–°", "å‡çº§", "æ–°ç‰ˆæœ¬", "å‘å¸ƒ"],
            "é—®é¢˜": ["é—®é¢˜", "bug", "é”™è¯¯", "æ•…éšœ"]
        }

        query_lower = query.lower()
        for topic, patterns in topic_patterns.items():
            if any(p in query_lower for p in patterns):
                topics.append(topic)

        return topics

    def format_query_result(self, parsed: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–è§£æç»“æœï¼ˆç”¨äºè°ƒè¯•ï¼‰

        Args:
            parsed: è§£æç»“æœ

        Returns:
            æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        """
        intent_map = {
            "summary": "æ€»ç»“æŸ¥è¯¢",
            "keyword": "å…³é”®è¯æŸ¥è¯¢",
            "topic": "ä¸»é¢˜æŸ¥è¯¢",
            "stats": "ç»Ÿè®¡æŸ¥è¯¢",
            "status": "çŠ¶æ€æŸ¥è¯¢"
        }

        result = f"ğŸ” æŸ¥è¯¢è§£æ:\n"
        result += f"æ„å›¾: {intent_map.get(parsed['intent'], parsed['intent'])}\n"

        if parsed.get("time_range"):
            result += f"æ—¶é—´èŒƒå›´: æœ€è¿‘{parsed['time_range']}å¤©\n"

        if parsed.get("keywords"):
            result += f"å…³é”®è¯: {', '.join(parsed['keywords'])}\n"

        result += f"ç½®ä¿¡åº¦: {parsed['confidence']:.0%}\n"

        return result


# åˆ›å»ºå…¨å±€æ„å›¾è§£æå™¨å®ä¾‹
intent_parser = None

def get_intent_parser():
    """è·å–å…¨å±€æ„å›¾è§£æå™¨å®ä¾‹"""
    global intent_parser
    if intent_parser is None:
        intent_parser = IntentParser()
    return intent_parser