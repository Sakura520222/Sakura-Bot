import os
import asyncio
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
from telethon import TelegramClient
from telethon.events import NewMessage
from openai import OpenAI
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„å˜é‡
load_dotenv()

# é…ç½®æ–‡ä»¶
PROMPT_FILE = "prompt.txt"
CONFIG_FILE = "config.json"

# é»˜è®¤æç¤ºè¯
DEFAULT_PROMPT = "è¯·æ€»ç»“ä»¥ä¸‹ Telegram æ¶ˆæ¯ï¼Œæå–æ ¸å¿ƒè¦ç‚¹å¹¶åˆ—å‡ºé‡è¦æ¶ˆæ¯çš„é“¾æ¥ï¼š\n\n"

# è¯»å–æç¤ºè¯å‡½æ•°
def load_prompt():
    """ä»æ–‡ä»¶ä¸­è¯»å–æç¤ºè¯ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤æç¤ºè¯"""
    try:
        with open(PROMPT_FILE, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯å¹¶åˆ›å»ºæ–‡ä»¶
        save_prompt(DEFAULT_PROMPT)
        return DEFAULT_PROMPT

# ä¿å­˜æç¤ºè¯å‡½æ•°
def save_prompt(prompt):
    """å°†æç¤ºè¯ä¿å­˜åˆ°æ–‡ä»¶ä¸­"""
    with open(PROMPT_FILE, "w", encoding="utf-8") as f:
        f.write(prompt)

# è¯»å–é…ç½®æ–‡ä»¶
def load_config():
    """ä»é…ç½®æ–‡ä»¶è¯»å–AIé…ç½®"""
    import json
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError:
        return {}

# ä¿å­˜é…ç½®æ–‡ä»¶
def save_config(config):
    """ä¿å­˜AIé…ç½®åˆ°æ–‡ä»¶"""
    import json
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

# åˆå§‹åŒ–æç¤ºè¯
CURRENT_PROMPT = load_prompt()

# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–é…ç½®
API_ID = os.getenv('TELEGRAM_API_ID')
API_HASH = os.getenv('TELEGRAM_API_HASH')
BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
# AI é…ç½® - ä»ç¯å¢ƒå˜é‡è·å–é»˜è®¤å€¼
LLM_API_KEY = os.getenv('LLM_API_KEY', os.getenv('DEEPSEEK_API_KEY'))
LLM_BASE_URL = os.getenv('LLM_BASE_URL', 'https://api.deepseek.com')
LLM_MODEL = os.getenv('LLM_MODEL', 'deepseek-chat')
TARGET_CHANNEL = os.getenv('TARGET_CHANNEL')
# ç®¡ç†å‘˜ ID åˆ—è¡¨ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–åè½¬ä¸ºæ•´æ•°åˆ—è¡¨
REPORT_ADMIN_IDS = os.getenv('REPORT_ADMIN_IDS', '')
# å¤„ç†ç®¡ç†å‘˜IDåˆ—è¡¨
ADMIN_LIST = []
if REPORT_ADMIN_IDS:
    # æ”¯æŒå¤šä¸ªç®¡ç†å‘˜IDï¼Œç”¨é€—å·åˆ†éš”
    ADMIN_LIST = [int(admin_id.strip()) for admin_id in REPORT_ADMIN_IDS.split(',')]
else:
    # å¦‚æœæ²¡æœ‰é…ç½®ç®¡ç†å‘˜IDï¼Œé»˜è®¤å‘é€ç»™è‡ªå·±
    ADMIN_LIST = ['me']

# åŠ è½½é…ç½®æ–‡ä»¶ï¼Œè¦†ç›–ç¯å¢ƒå˜é‡é»˜è®¤å€¼
config = load_config()
if config:
    LLM_API_KEY = config.get('api_key', LLM_API_KEY)
    LLM_BASE_URL = config.get('base_url', LLM_BASE_URL)
    LLM_MODEL = config.get('model', LLM_MODEL)

# åˆå§‹åŒ– AI å®¢æˆ·ç«¯
client_llm = OpenAI(
    api_key=LLM_API_KEY, 
    base_url=LLM_BASE_URL
)

async def fetch_last_week_messages():
    """æŠ“å–è¿‡å»ä¸€å‘¨çš„é¢‘é“æ¶ˆæ¯"""
    # ç¡®ä¿ API_ID æ˜¯æ•´æ•°
    async with TelegramClient('session_name', int(API_ID), API_HASH) as client:
        last_week = datetime.now(timezone.utc) - timedelta(days=7)
        messages_list = []
        
        print(f"æ­£åœ¨æŠ“å–é¢‘é“: {TARGET_CHANNEL}...")
        
        async for message in client.iter_messages(TARGET_CHANNEL, offset_date=last_week, reverse=True):
            if message.text:
                # åŠ¨æ€è·å–é¢‘é“åç”¨äºç”Ÿæˆé“¾æ¥
                channel_part = TARGET_CHANNEL.split('/')[-1]
                msg_link = f"https://t.me/{channel_part}/{message.id}"
                messages_list.append(f"å†…å®¹: {message.text[:500]}\né“¾æ¥: {msg_link}")
        
        return messages_list

def analyze_with_ai(messages):
    """è°ƒç”¨ AI è¿›è¡Œæ±‡æ€»"""
    if not messages:
        return "æœ¬å‘¨æ— æ–°åŠ¨æ€ã€‚"

    context_text = "\n\n---\n\n".join(messages)
    
    prompt = f"{CURRENT_PROMPT}{context_text}"

    try:
        response = client_llm.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èµ„è®¯æ‘˜è¦åŠ©æ‰‹ï¼Œæ“…é•¿æå–é‡ç‚¹å¹¶ä¿æŒå®¢è§‚ã€‚"},
                {"role": "user", "content": prompt},
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI åˆ†æå¤±è´¥: {e}"

async def send_report(summary_text):
    """å‘é€æŠ¥å‘Š"""
    client = TelegramClient('bot_session', int(API_ID), API_HASH)
    async with client:
        await client.start(bot_token=BOT_TOKEN)
        # å‘æ‰€æœ‰ç®¡ç†å‘˜å‘é€æ¶ˆæ¯
        for admin_id in ADMIN_LIST:
            try:
                await send_long_message(client, admin_id, summary_text)
                print(f"æˆåŠŸå‘ç®¡ç†å‘˜ {admin_id} å‘é€æŠ¥å‘Š")
            except Exception as e:
                print(f"å‘ç®¡ç†å‘˜ {admin_id} å‘é€æŠ¥å‘Šå¤±è´¥: {e}")

async def main_job():
    print(f"ä»»åŠ¡å¯åŠ¨: {datetime.now()}")
    messages = await fetch_last_week_messages()
    summary = analyze_with_ai(messages)
    await send_report(f"ğŸ“‹ **é¢‘é“å‘¨æŠ¥æ±‡æ€»**\n\n{summary}")

# å…¨å±€å˜é‡ï¼Œç”¨äºè·Ÿè¸ªæ­£åœ¨è®¾ç½®æç¤ºè¯çš„ç”¨æˆ·
setting_prompt_users = set()
# å…¨å±€å˜é‡ï¼Œç”¨äºè·Ÿè¸ªæ­£åœ¨è®¾ç½®AIé…ç½®çš„ç”¨æˆ·
setting_ai_config_users = set()
# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨æ­£åœ¨é…ç½®ä¸­çš„AIå‚æ•°
current_ai_config = {}

async def send_long_message(client, chat_id, text, max_length=4000):
    """åˆ†æ®µå‘é€é•¿æ¶ˆæ¯"""
    if len(text) <= max_length:
        await client.send_message(chat_id, text)
        return
    
    # åˆ†æ®µå‘é€
    parts = []
    current_part = ""
    for line in text.split('\n'):
        # æ£€æŸ¥æ·»åŠ å½“å‰è¡Œæ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(current_part) + len(line) + 1 <= max_length:
            current_part += line + '\n'
        else:
            # å¦‚æœå½“å‰éƒ¨åˆ†ä¸ä¸ºç©ºï¼Œæ·»åŠ åˆ°åˆ—è¡¨
            if current_part:
                parts.append(current_part.strip())
            # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦è¶…è¿‡é™åˆ¶
            if len(line) > max_length:
                # å¯¹è¶…é•¿è¡Œè¿›è¡Œè¿›ä¸€æ­¥åˆ†å‰²
                for i in range(0, len(line), max_length):
                    parts.append(line[i:i+max_length])
            else:
                current_part = line + '\n'
    
    # æ·»åŠ æœ€åä¸€éƒ¨åˆ†
    if current_part:
        parts.append(current_part.strip())
    
    # å‘é€æ‰€æœ‰éƒ¨åˆ†
    for i, part in enumerate(parts):
        await client.send_message(chat_id, f"ğŸ“‹ **é¢‘é“å‘¨æŠ¥æ±‡æ€» ({i+1}/{len(parts)})**\n\n{part}")

async def handle_manual_summary(event):
    """å¤„ç†/ç«‹å³æ€»ç»“å‘½ä»¤"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦ä¸ºç®¡ç†å‘˜
    sender_id = event.sender_id
    if sender_id not in ADMIN_LIST and ADMIN_LIST != ['me']:
        await event.reply("æ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤å‘½ä»¤")
        return
    
    # å‘é€æ­£åœ¨å¤„ç†çš„æ¶ˆæ¯
    await event.reply("æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆæœ¬å‘¨æ€»ç»“...")
    
    # æ‰§è¡Œæ€»ç»“ä»»åŠ¡
    try:
        messages = await fetch_last_week_messages()
        summary = analyze_with_ai(messages)
        await send_long_message(event.client, sender_id, summary)
    except Exception as e:
        await event.reply(f"ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")

async def handle_show_prompt(event):
    """å¤„ç†/showpromptå‘½ä»¤ï¼Œæ˜¾ç¤ºå½“å‰æç¤ºè¯"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦ä¸ºç®¡ç†å‘˜
    sender_id = event.sender_id
    if sender_id not in ADMIN_LIST and ADMIN_LIST != ['me']:
        await event.reply("æ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤å‘½ä»¤")
        return
    
    await event.reply(f"å½“å‰æç¤ºè¯ï¼š\n\n{CURRENT_PROMPT}")

async def handle_set_prompt(event):
    """å¤„ç†/setpromptå‘½ä»¤ï¼Œè§¦å‘æç¤ºè¯è®¾ç½®æµç¨‹"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦ä¸ºç®¡ç†å‘˜
    sender_id = event.sender_id
    if sender_id not in ADMIN_LIST and ADMIN_LIST != ['me']:
        await event.reply("æ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤å‘½ä»¤")
        return
    
    # æ·»åŠ ç”¨æˆ·åˆ°æ­£åœ¨è®¾ç½®æç¤ºè¯çš„é›†åˆä¸­
    setting_prompt_users.add(sender_id)
    await event.reply("è¯·å‘é€æ–°çš„æç¤ºè¯ï¼Œæˆ‘å°†ä½¿ç”¨å®ƒæ¥ç”Ÿæˆæ€»ç»“ã€‚\n\nå½“å‰æç¤ºè¯ï¼š\n" + CURRENT_PROMPT)

async def handle_prompt_input(event):
    """å¤„ç†ç”¨æˆ·è¾“å…¥çš„æ–°æç¤ºè¯"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦åœ¨è®¾ç½®æç¤ºè¯çš„é›†åˆä¸­
    sender_id = event.sender_id
    if sender_id not in setting_prompt_users:
        return
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å‘½ä»¤æ¶ˆæ¯ï¼Œå¦‚æœæ˜¯åˆ™ä¸å¤„ç†
    if event.text.startswith('/'):
        await event.reply("è¯·å‘é€æç¤ºè¯å†…å®¹ï¼Œä¸è¦å‘é€å‘½ä»¤ã€‚å¦‚æœè¦å–æ¶ˆè®¾ç½®ï¼Œè¯·é‡æ–°å‘é€å‘½ä»¤ã€‚")
        return
    
    # è·å–æ–°æç¤ºè¯
    new_prompt = event.text.strip()
    
    # æ›´æ–°å…¨å±€å˜é‡å’Œæ–‡ä»¶
    global CURRENT_PROMPT
    CURRENT_PROMPT = new_prompt
    save_prompt(new_prompt)
    
    # ä»é›†åˆä¸­ç§»é™¤ç”¨æˆ·
    setting_prompt_users.remove(sender_id)
    
    await event.reply(f"æç¤ºè¯å·²æ›´æ–°ä¸ºï¼š\n\n{new_prompt}")

async def handle_show_ai_config(event):
    """å¤„ç†/showaicfgå‘½ä»¤ï¼Œæ˜¾ç¤ºå½“å‰AIé…ç½®"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦ä¸ºç®¡ç†å‘˜
    sender_id = event.sender_id
    if sender_id not in ADMIN_LIST and ADMIN_LIST != ['me']:
        await event.reply("æ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤å‘½ä»¤")
        return
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    config_info = f"å½“å‰AIé…ç½®ï¼š\n\n"
    config_info += f"API Keyï¼š{LLM_API_KEY[:10]}...{LLM_API_KEY[-10:] if len(LLM_API_KEY) > 20 else LLM_API_KEY}\n"
    config_info += f"Base URLï¼š{LLM_BASE_URL}\n"
    config_info += f"Modelï¼š{LLM_MODEL}\n"
    
    await event.reply(config_info)

async def handle_set_ai_config(event):
    """å¤„ç†/setaicfgå‘½ä»¤ï¼Œè§¦å‘AIé…ç½®è®¾ç½®æµç¨‹"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦ä¸ºç®¡ç†å‘˜
    sender_id = event.sender_id
    if sender_id not in ADMIN_LIST and ADMIN_LIST != ['me']:
        await event.reply("æ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤å‘½ä»¤")
        return
    
    # æ·»åŠ ç”¨æˆ·åˆ°æ­£åœ¨è®¾ç½®AIé…ç½®çš„é›†åˆä¸­
    setting_ai_config_users.add(sender_id)
    # åˆå§‹åŒ–å½“å‰é…ç½®
    global current_ai_config
    current_ai_config = {
        'api_key': LLM_API_KEY,
        'base_url': LLM_BASE_URL,
        'model': LLM_MODEL
    }
    
    await event.reply("è¯·ä¾æ¬¡å‘é€ä»¥ä¸‹AIé…ç½®å‚æ•°ï¼Œæˆ–å‘é€/skipè·³è¿‡ï¼š\n\n1. API Key\n2. Base URL\n3. Model\n\nå‘é€/cancelå–æ¶ˆè®¾ç½®")

async def handle_ai_config_input(event):
    """å¤„ç†ç”¨æˆ·è¾“å…¥çš„AIé…ç½®å‚æ•°"""
    # æ£€æŸ¥å‘é€è€…æ˜¯å¦åœ¨è®¾ç½®AIé…ç½®çš„é›†åˆä¸­
    sender_id = event.sender_id
    if sender_id not in setting_ai_config_users:
        return
    
    # æ£€æŸ¥å‘½ä»¤
    if event.text == '/cancel':
        # å–æ¶ˆè®¾ç½®
        setting_ai_config_users.remove(sender_id)
        await event.reply("å·²å–æ¶ˆAIé…ç½®è®¾ç½®")
        return
    
    # è·å–å½“å‰é…ç½®çŠ¶æ€
    global current_ai_config
    config_step = len([k for k, v in current_ai_config.items() if v is not None]) + 1
    
    # æ ¹æ®å½“å‰æ­¥éª¤å¤„ç†è¾“å…¥
    if config_step == 1:
        # å¤„ç†API Key
        if event.text != '/skip':
            current_ai_config['api_key'] = event.text.strip()
        await event.reply(f"API Keyå·²è®¾ç½®ä¸ºï¼š{current_ai_config['api_key'][:10]}...{current_ai_config['api_key'][-10:] if len(current_ai_config['api_key']) > 20 else current_ai_config['api_key']}\n\nè¯·å‘é€Base URLï¼Œæˆ–å‘é€/skipè·³è¿‡")
    elif config_step == 2:
        # å¤„ç†Base URL
        if event.text != '/skip':
            current_ai_config['base_url'] = event.text.strip()
        await event.reply(f"Base URLå·²è®¾ç½®ä¸ºï¼š{current_ai_config['base_url']}\n\nè¯·å‘é€Modelï¼Œæˆ–å‘é€/skipè·³è¿‡")
    elif config_step == 3:
        # å¤„ç†Model
        if event.text != '/skip':
            current_ai_config['model'] = event.text.strip()
        
        # ä¿å­˜é…ç½®
        save_config(current_ai_config)
        
        # æ›´æ–°å…¨å±€å˜é‡
        global LLM_API_KEY, LLM_BASE_URL, LLM_MODEL, client_llm
        LLM_API_KEY = current_ai_config['api_key']
        LLM_BASE_URL = current_ai_config['base_url']
        LLM_MODEL = current_ai_config['model']
        
        # é‡æ–°åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        client_llm = OpenAI(
            api_key=LLM_API_KEY, 
            base_url=LLM_BASE_URL
        )
        
        # ä»é›†åˆä¸­ç§»é™¤ç”¨æˆ·
        setting_ai_config_users.remove(sender_id)
        
        # æ˜¾ç¤ºæœ€ç»ˆé…ç½®
        config_info = f"AIé…ç½®å·²æ›´æ–°ï¼š\n\n"
        config_info += f"API Keyï¼š{LLM_API_KEY[:10]}...{LLM_API_KEY[-10:] if len(LLM_API_KEY) > 20 else LLM_API_KEY}\n"
        config_info += f"Base URLï¼š{LLM_BASE_URL}\n"
        config_info += f"Modelï¼š{LLM_MODEL}\n"
        
        await event.reply(config_info)

async def main():
    # åˆå§‹åŒ–è°ƒåº¦å™¨
    scheduler = AsyncIOScheduler()
    # æ¯å‘¨ä¸€æ—© 9 ç‚¹æ‰§è¡Œ
    scheduler.add_job(main_job, 'cron', day_of_week='mon', hour=9, minute=0)
    
    # æµ‹è¯•è¿è¡Œï¼šå¯åŠ¨å³è¿è¡Œä¸€æ¬¡
    # await main_job()
    
    # å¯åŠ¨æœºå™¨äººå®¢æˆ·ç«¯ï¼Œå¤„ç†å‘½ä»¤
    client = TelegramClient('bot_session', int(API_ID), API_HASH)
    
    # æ·»åŠ å‘½ä»¤å¤„ç†ï¼Œæ”¯æŒä¸­è‹±æ–‡å‘½ä»¤
    client.add_event_handler(handle_manual_summary, NewMessage(pattern='/ç«‹å³æ€»ç»“|/summary'))
    client.add_event_handler(handle_show_prompt, NewMessage(pattern='/showprompt|/show_prompt|/æŸ¥çœ‹æç¤ºè¯'))
    client.add_event_handler(handle_set_prompt, NewMessage(pattern='/setprompt|/set_prompt|/è®¾ç½®æç¤ºè¯'))
    client.add_event_handler(handle_show_ai_config, NewMessage(pattern='/showaicfg|/show_aicfg|/æŸ¥çœ‹AIé…ç½®'))
    client.add_event_handler(handle_set_ai_config, NewMessage(pattern='/setaicfg|/set_aicfg|/è®¾ç½®AIé…ç½®'))
    # åªå¤„ç†éå‘½ä»¤æ¶ˆæ¯ä½œä¸ºæç¤ºè¯æˆ–AIé…ç½®è¾“å…¥
    client.add_event_handler(handle_prompt_input, NewMessage(func=lambda e: not e.text.startswith('/')))
    client.add_event_handler(handle_ai_config_input, NewMessage(func=lambda e: True))
    
    # å¯åŠ¨å®¢æˆ·ç«¯
    await client.start(bot_token=BOT_TOKEN)
    
    # æ³¨å†Œæœºå™¨äººå‘½ä»¤
    from telethon.tl.functions.bots import SetBotCommandsRequest
    from telethon.tl.types import BotCommand, BotCommandScopeDefault
    
    commands = [
        BotCommand(command="summary", description="ç«‹å³ç”Ÿæˆæœ¬å‘¨é¢‘é“æ¶ˆæ¯æ±‡æ€»"),
        BotCommand(command="showprompt", description="æŸ¥çœ‹å½“å‰æç¤ºè¯"),
        BotCommand(command="setprompt", description="è®¾ç½®è‡ªå®šä¹‰æç¤ºè¯"),
        BotCommand(command="showaicfg", description="æŸ¥çœ‹AIé…ç½®"),
        BotCommand(command="setaicfg", description="è®¾ç½®AIé…ç½®")
    ]
    
    await client(SetBotCommandsRequest(
        scope=BotCommandScopeDefault(),
        lang_code="zh",
        commands=commands
    ))
    
    print("å®šæ—¶ç›‘æ§å·²å¯åŠ¨...")
    print("æœºå™¨äººå·²å¯åŠ¨ï¼Œæ­£åœ¨ç›‘å¬å‘½ä»¤...")
    print("æœºå™¨äººå‘½ä»¤å·²æ³¨å†Œå®Œæˆ...")
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()
    
    # ä¿æŒå®¢æˆ·ç«¯è¿è¡Œ
    await client.run_until_disconnected()

if __name__ == "__main__":
    # æ£€æŸ¥å¿…è¦å˜é‡æ˜¯å¦å­˜åœ¨
    required_vars = [API_ID, API_HASH, BOT_TOKEN, LLM_API_KEY]
    if not all(required_vars):
        print("é”™è¯¯: è¯·ç¡®ä¿ .env æ–‡ä»¶ä¸­é…ç½®äº†æ‰€æœ‰å¿…è¦çš„ API å‡­è¯ã€‚")
    else:
        # å¯åŠ¨ä¸»å‡½æ•°
        asyncio.run(main())